<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Maria Parelli - Mary Parelli</title>

    <meta name="author" content="Maria Parelli">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Maria Parelli
                </p>
                <p>I am a Ph.D. student in the <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/home/">Autonomous Vision Group</a> at the <a href="https://uni-tuebingen.de/en">University of TÃ¼bingen</a>, led by <a href="https://www.cvlibs.net/index.php">Prof. Andreas Geiger</a>, as part of the <a href="https://imprs.is.mpg.de/">International Max Planck Research School for Intelligent Systems (IMPRS-IS)</a>. My focus area is 3D generative modeling.
                </p>
                <p>
                  Prior to this, I completed my Master's in Data Science at <a href="https://ethz.ch/en.html">ETH Zurich</a> under the supervision of <a href="https://ait.ethz.ch/people/hilliges">Prof. Otmar Hilliges</a>. Earlier, I earned a Diploma in Electrical and Computer Engineering from the <a href="https://www.ntua.gr/en">National Technical University of Athens</a>, where I worked with <a href="http://cvsp.cs.ntua.gr/maragos">Prof. Petros Maragos</a>. Before joining ETH, I worked as an ML Engineer/Researcher at <a href="https://deeplab.ai">Deeplab</a> on interpretable vision-language understanding.
                </p>
                <p style="text-align:center">
                  <a href="mailto:maryparelli@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=ipSS2ToAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/MaryParelli">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/mparelli">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/me2.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/me2.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning and generative AI.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/hold.png" alt="fast-texture" width="250" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://zc-alexfan.github.io/hold">
                <span class="papertitle">HOLD: Category-agnostic 3d reconstruction of interacting hands and objects from video</span>
              </a>
              <br>
              Zicong Fan,
              <strong>Maria Parelli</strong>, 
              Maria Eleni Kadoglou,
              Muhammed Kocabas, 
              Xu Chen, 
              Michael J. Black,
              Otmar Hilliges
              <br>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://zc-alexfan.github.io/hold">project page</a>
              /
              <a href="https://arxiv.org/abs/2311.18448">paper</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/multi_clip.png" alt="fast-texture" width="250" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://proceedings.bmvc2023.org/748/">
                <span class="papertitle">Multi-CLIP: Contrastive Vision-Language Pre-training for Question Answering tasks in 3D Scenes</span>
              </a>
              <br>
              Alexandros Delitzas*, 
              <strong>Maria Parelli</strong>*, 
              Nikolas Hars, 
              Georgios Vlassis, 
              Sotirios Anagnostidis, 
              Gregor Bachmann, 
              Thomas Hofmann
              <br>
              <em>BMVC</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://proceedings.bmvc2023.org/748/">project page</a>
              /
              <a href="https://arxiv.org/abs/2306.02329">paper</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/clip_guided.png" alt="fast-texture" width="200" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2304.06061">
                <span class="papertitle">CLIP-Guided Vision-Language Pre-training for Question Answering in 3D Scenes</span>
              </a>
              <br>
              <strong>Maria Parelli</strong>*, 
              Alexandros Delitzas*, 
              Nikolas Hars, 
              Georgios Vlassis, 
              Sotirios Anagnostidis, 
              Gregor Bachmann, 
              Thomas Hofmann
              <br>
              <em>CVPR Workshops</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2304.06061">paper</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/interpretable.png" alt="fast-texture" width="220" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2309.03726">
                <span class="papertitle">Interpretable visual question answering via reasoning supervision</span>
              </a>
              <br>
              <strong>Maria Parelli</strong>, 
              Dimitrios Mallis, 
              Markos Diomataris, 
              Vassilis Pitsikalis
              <br>
              <em>ICIP</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2309.03726">paper</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/spatio_temporal.png" alt="fast-texture" width="240" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9746971">
                <span class="papertitle">Spatio-temporal graph convolutional networks for continuous sign language recognition</span>
              </a>
              <br>
              <strong>Maria Parelli</strong>*, 
              Katerina Papadimitriou, 
              Gerasimos Potamianos, 
              Georgios Pavlakos, 
              Petros Maragos
              <br>
              <em>ICASSP</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9746971">paper</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/exploiting.png" alt="fast-texture" width="250" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-66096-3_18">
                <span class="papertitle">Exploiting 3d hand pose estimation in deep learning-based sign language recognition from rgb videos</span>
              </a>
              <br>
              <strong>Maria Parelli</strong>*, 
              Katerina Papadimitriou, 
              Gerasimos Potamianos, 
              Georgios Pavlakos, 
              Petros Maragos
              <br>
              <em>ECCV Workshops</em>, 2020
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-66096-3_18">paper</a>
            </td>
          </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Design and source code from <a href="https://jonbarron.info">Jon Barron's wesite</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
